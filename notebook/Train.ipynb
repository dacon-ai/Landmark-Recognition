{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dacon/Dacon/HDD_02/landmark/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(fff='/home/dacon/.local/share/jupyter/runtime/kernel-3bec9b54-5302-4fa1-b754-b82563a43912.json', gpus='1', test_csv='../data/test_labels_0.csv', train_csv='../data/train_labels_0.csv', train_dir='../data/train/')\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Compute dtype: float16\n",
      "Variable dtype: float32\n",
      "Setting strategy to OneDeviceStrategy(device='GPU')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "import glob\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import shutil\n",
    "import tqdm as tqdm\n",
    "import random\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import wandb\n",
    "\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from utils.utils import *\n",
    "from dataset.dataset import *\n",
    "from model.model import DistributedModel\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-gpus', '--gpus', dest=\"gpus\", default=\"1\")\n",
    "parser.add_argument('-train_dir', '--train_dir', dest=\"train_dir\", default='../data/train/')\n",
    "parser.add_argument('-train_csv', '--train_csv', dest=\"train_csv\", default='../data/train_labels_0.csv')\n",
    "parser.add_argument('-test_csv', '--test_csv', dest=\"test_csv\", default='../data/test_labels_0.csv')\n",
    "parser.add_argument('-save_path', '--save_path', dest=\"save_path\", default='../output/checkpoint/checkpoint')\n",
    "parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "options = parser.parse_args()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= options.gpus\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "num_gpus = len(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(num_gpus, \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "    policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "    tf.keras.mixed_precision.experimental.set_policy(policy)\n",
    "    print('Compute dtype: %s' % policy.compute_dtype)\n",
    "    print('Variable dtype: %s' % policy.variable_dtype)\n",
    "\n",
    "    \n",
    "if num_gpus == 0:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device='CPU')\n",
    "    print(\"Setting strategy to OneDeviceStrategy(device='CPU')\")\n",
    "elif num_gpus == 1:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device='GPU')\n",
    "    print(\"Setting strategy to OneDeviceStrategy(device='GPU')\")\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(\"Setting strategy to MirroredStrategy()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    input_path = options.train_dir\n",
    "    file_name = options.train_csv\n",
    "    query = '*/*.jpg'\n",
    "    \n",
    "    train_df, mapping = read_train_file(input_path, file_name, query)\n",
    "    file_name = options.test_csv\n",
    "    submission_df = read_submission_file(input_path, file_name, query, train=True)\n",
    "    \n",
    "    config = {\n",
    "    'learning_rate': 1e-3,\n",
    "    'momentum': 0.9,\n",
    "    'scale': 30,\n",
    "    'margin': 0.1,\n",
    "    'clip_grad': 10.0,\n",
    "    'n_epochs': 50,\n",
    "    'batch_size': 256,\n",
    "    'input_size': (224, 224, 3),\n",
    "    'n_classes': len(train_df['label'].unique()),\n",
    "    'dense_units': 512,\n",
    "    'dropout_rate': 0.0,\n",
    "    'save_interval': 50,\n",
    "    'wandb':True\n",
    "    }\n",
    "    \n",
    "    \n",
    "    train_ds = create_dataset(\n",
    "        df=train_df,\n",
    "        training=True,\n",
    "        batch_size=config['batch_size'],\n",
    "        input_size=config['input_size'],\n",
    "    )\n",
    "\n",
    "    test_ds = create_dataset(\n",
    "            df=submission_df,\n",
    "            training=False,\n",
    "            batch_size=config['batch_size'],\n",
    "            input_size=config['input_size'],\n",
    "        )\n",
    "    \n",
    "    with strategy.scope():\n",
    "\n",
    "        optimizer = tf.keras.optimizers.SGD(config['learning_rate'], momentum=config['momentum'])\n",
    "\n",
    "        dist_model = DistributedModel(\n",
    "            input_size=config['input_size'],\n",
    "            n_classes=config['n_classes'],\n",
    "            batch_size=config['batch_size'],\n",
    "            finetuned_weights=None,\n",
    "            dense_units=config['dense_units'],\n",
    "            dropout_rate=config['dropout_rate'],\n",
    "            scale=config['scale'],\n",
    "            margin=config['margin'],\n",
    "            optimizer=optimizer,\n",
    "            strategy=strategy,\n",
    "            mixed_precision=True,\n",
    "            clip_grad=config['clip_grad'],\n",
    "            wandb_log=config['wandb'])\n",
    "\n",
    "        dist_model.train(\n",
    "            train_ds=train_ds, \n",
    "            valid_ds=test_ds,\n",
    "            epochs=config['n_epochs'], \n",
    "            save_path=options.save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "landmark",
   "language": "python",
   "name": "landmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
